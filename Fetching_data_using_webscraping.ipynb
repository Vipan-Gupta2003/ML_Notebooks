{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jV91BkMp8vM_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "requests.get('https://www.ambitionbox.com/list-of-companies?page=1')"
      ],
      "metadata": {
        "id": "B3ydh036-EaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# response 403 means bad request"
      ],
      "metadata": {
        "id": "CWn25gH_-o4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "requests.get('https://www.ambitionbox.com/list-of-companies?page=1').text\n",
        "# it will give the text related to it access"
      ],
      "metadata": {
        "id": "aqFKGxYM-wOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to access the data we have to disgise this request a browser reqeust\n",
        "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'}\n",
        "webpage = requests.get('https://www.ambitionbox.com/list-of-companies?page=1',headers=headers).text\n",
        "# It will give the full HTML code"
      ],
      "metadata": {
        "id": "w7RHhD_m-y1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup=BeautifulSoup(webpage, 'lxml')#lxml is a HTML Parser. it make traversing html easy."
      ],
      "metadata": {
        "id": "Q5MKkiqS_5Vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(soup.prettify()) #format HTML code"
      ],
      "metadata": {
        "id": "C-tTCQ58A-OE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " soup.find_all('h1')#it will find all h1 tags"
      ],
      "metadata": {
        "id": "uwTweftSBgiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find_all('h1')[0]# it will give 0th h1 tag out of h1 tag lists"
      ],
      "metadata": {
        "id": "1yVl7dOaDE3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find_all('h1')[0].text# it will give text of that h1tag"
      ],
      "metadata": {
        "id": "MYg-UL1_DZGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(soup.find_all('h2'))"
      ],
      "metadata": {
        "id": "XhGNp7k9DoEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in soup.find_all('h2'):\n",
        "  print(i.text.strip())# strip is used to remove formatting"
      ],
      "metadata": {
        "id": "Z7xbdq8DD8Fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in soup.find_all('p'):\n",
        "  print(i.text.strip())\n",
        "\n",
        "  # As everything is almost used for everything . so we are unable to differentiate between data"
      ],
      "metadata": {
        "id": "BOssHT2WFdpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find_all('p', class_='rating')"
      ],
      "metadata": {
        "id": "8PIJO7cVGKSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find_all('a',class_ = 'review-count')"
      ],
      "metadata": {
        "id": "qm9XG0xoHBtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instead of fetching this way we should be fetching the whole container"
      ],
      "metadata": {
        "id": "LNzZK7D7HOHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "company = soup.find_all('div',class_='company-content-wrapper')"
      ],
      "metadata": {
        "id": "GZtsvwX8Hv8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(company)"
      ],
      "metadata": {
        "id": "NUXvFz2yIE-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " company[0].find_all('p',class_='infoEntity')[0].text.split()"
      ],
      "metadata": {
        "id": "cqlOaLWSK7B_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name=[]\n",
        "rating =[]\n",
        "reviews=[]\n",
        "ctype =[]\n",
        "hq = []\n",
        "old =[]\n",
        "employees =[]\n",
        "for i in company:\n",
        "  # i.find_all('h2')#it will allow us to find h2 tag inside every div (we can use find() instead)\n",
        "  print(i.find('h2').text.split())\n",
        "  name.append(i.find('h2').text.split())\n",
        "  rating.append(i.find('p',class_='rating').split().text)\n",
        "  reviews.append(i.find('a',class_='review-count').text.split())\n",
        "  ctype.append(i.find_all('p',class_='infoEntity')[0].text.strip())\n",
        "  hq.append(i.find_all('p',class_='infoEntity')[0].text.strip())\n",
        "  old.append(i.find_all('p',class_='infoEntity')[0].text.strip())\n",
        "  try:\n",
        "    employees.append(i.find_all('p',class_='infoEntity')[0].text.strip())\n",
        "  except:\n",
        "    employees.append(np.nan)"
      ],
      "metadata": {
        "id": "vDwd6bhvIK7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d= {'name':name , 'rating'=rating,'reviews':reviews,'ctype':ctype, 'hq':hq,'old':old, 'employees':employees}"
      ],
      "metadata": {
        "id": "iGXfdMsUh0DR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(d)"
      ],
      "metadata": {
        "id": "pFJwBQz6i7iF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "euxnYlTwjA4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "OF0h31OPjEnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final=pd.DataFrame()\n",
        "for j in range(1,1001):\n",
        "  webpage=requests.get('https://www.ambitionbox.com/list-of-companies?page={}'.format(j)).text\n",
        "  soup=BeautifulSoup(webpage,'lxml')\n",
        "  company=soup.find_all('div',class_='company-content-wrapper')\n",
        "  name=[]\n",
        "  rating=[]\n",
        "  reviews=[]\n",
        "  ctype=[]\n",
        "  hq=[]\n",
        "  how_old=[]\n",
        "  no_of_employee=[]\n",
        "\n",
        "  for i in company:\n",
        "\n",
        "    try:\n",
        "       name.append(i.find('h2').text.strip())\n",
        "    except:\n",
        "       name.append(np.nan)\n",
        "\n",
        "    try:\n",
        "       rating.append(i.find('p',class_='rating').text.strip())\n",
        "    except:\n",
        "       rating.append(np.nan)\n",
        "\n",
        "    try:\n",
        "\n",
        "      reviews.append(i.find('a' , class_='review-count').text.strip())\n",
        "    except:\n",
        "      reviews.append(np.nan)\n",
        "\n",
        "    try:\n",
        "\n",
        "      ctype.append(i.find_all('p',class_='infoEntity')[0].text.strip())\n",
        "    except:\n",
        "      ctype.append(np.nan)\n",
        "    try:\n",
        "\n",
        "      hq.append(i.find_all('p',class_='infoEntity')[1].text.strip())\n",
        "    except:\n",
        "      hq.append(np.nan)\n",
        "\n",
        "    try:\n",
        "\n",
        "      how_old.append(i.find_all('p',class_='infoEntity')[2].text.strip())\n",
        "    except:\n",
        "      how_old.append(np.nan)\n",
        "    try:\n",
        "      no_of_employee.append(i.find_all('p',class_='infoEntity')[3].text.strip())\n",
        "    except:\n",
        "      no_of_employee.append(np.nan)\n",
        "\n",
        "\n",
        "  df=pd.DataFrame({'name':name,\n",
        "    'rating':rating,\n",
        "    'reviews':reviews,\n",
        "    'company_type':ctype,\n",
        "    'Head_Quarters':hq,\n",
        "    'Company_Age':how_old,\n",
        "    'No_of_Employee':no_of_employee,\n",
        "    })\n",
        "\n",
        "  final=final.append(df,ignore_index=True)\n"
      ],
      "metadata": {
        "id": "JdaiY90-jn5M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}